{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "c:\\program files\\python36\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, Activation, \\\n",
    "BatchNormalization, Input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    path = path.replace('\\\\','/')\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상\n",
    "img_nd = r'D:\\Working_dir\\Ehwlfkfdlsp\\fog\\normal_day\\normal_day'\n",
    "img_nn = r'D:\\Working_dir\\Ehwlfkfdlsp\\fog\\normal_night\\normal_night'\n",
    "\n",
    "# 안개\n",
    "img_fd = r'D:\\Working_dir\\Ehwlfkfdlsp\\fog\\fog_day\\fog_day\\fog_day'\n",
    "img_fn = r'D:\\Working_dir\\Ehwlfkfdlsp\\fog\\fog_night\\fog_night\\fog_night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = read_img(img_nd)\n",
    "nn = read_img(img_nn)\n",
    "\n",
    "fd = read_img(img_fd)\n",
    "fn = read_img(img_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi0 = [(2, 0), (3, 0), (4, 0), (5, 0), (6, 0), (4, 0), (8, 0), (9, 0)]\n",
    "roi1 = [(5, 1), (6, 1), (7, 1), (8, 1), (9, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "width , height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = r'D:\\Working_dir\\Ehwlfkfdlsp\\fog\\nor_fog'\n",
    "source_path = source_path.replace('\\\\', '/')\n",
    "# categories = os.listdir(source_path)\n",
    "categories = ['normal_day', 'normal_night', 'fog_day', 'fog_night']\n",
    "sample_number = 500\n",
    "classnum = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = [], []\n",
    "for cat in categories:\n",
    "    path = f'{source_path}/{cat}'\n",
    "#     print(path)\n",
    "    img_file_list = fnmatch.filter(os.listdir(path), '*.jpg')\n",
    "    sample_number = min(len(img_file_list), sample_number)\n",
    "    if sample_number == 0:\n",
    "        print(f'No image fil exists in source path: {path}.')\n",
    "        break\n",
    "    elif len(img_file_list) < sample_number:\n",
    "        print(f'Number of {cat} image ({len(img_file_list)}) is smaller'\n",
    "                           f' than SAMPLE NUMBER({sample_number}).')\n",
    "        \n",
    "    random.shuffle(img_file_list)\n",
    "    \n",
    "    test_number = round(sample_number * 0.2)\n",
    "    train_number = sample_number - test_number\n",
    "    label = categories.index(cat)\n",
    "    \n",
    "    for img_file in img_file_list[:train_number]:\n",
    "        train_set.append([img_file, label])\n",
    "    for img_file in img_file_list[train_number:sample_number]:\n",
    "        test_set.append([img_file, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_set)\n",
    "random.shuffle(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, train_label = [], []\n",
    "\n",
    "for img_file, img_label in train_set:\n",
    "    try:\n",
    "        path = ''.join([str(source_path).replace('\\\\', '/'), '/', str(categories[img_label])])\n",
    "        img_file_path = ''.join([str(path), '/', str(img_file)])\n",
    "        img = cv2.imread(img_file_path)\n",
    "        for (i, j) in roi0:\n",
    "            x, y = i * width, j * height\n",
    "            roi_img = img[y:y + width, x:x + height]\n",
    "            train_img.append(roi_img)\n",
    "            train_label.append(img_label)\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(f'image processing failed at {str(img_file)}')\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img1, train_label1 = [], []\n",
    "\n",
    "for img_file, img_label in train_set:\n",
    "    try:\n",
    "        path = ''.join([str(source_path).replace('\\\\', '/'), '/', str(categories[img_label])])\n",
    "        img_file_path = ''.join([str(path), '/', str(img_file)])\n",
    "        img = cv2.imread(img_file_path)\n",
    "        for (i, j) in roi1:\n",
    "            x, y = i * width, j * height\n",
    "            roi_img = img[y:y + width, x:x + height]\n",
    "            train_img1.append(roi_img)\n",
    "            train_label1.append(img_label)\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(f'image processing failed at {str(img_file)}')\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image, test_label = [], []\n",
    "for img_file, img_label in test_set:\n",
    "    try:\n",
    "        path = ''.join([str(source_path).replace('\\\\', '/'), '/', str(categories[img_label])])\n",
    "        img_file_path = ''.join([str(path), \"/\", str(img_file)])\n",
    "        img = cv2.imread(img_file_path)\n",
    "        for (i, j) in roi0:\n",
    "            x, y = i * width, j * height\n",
    "            roi_img = img[y:y + width, x:x + height]\n",
    "            test_image.append(roi_img)\n",
    "            test_label.append(img_label)\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(f'image processing failed at {str(img_file)}')\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image1, test_label1 = [], []\n",
    "for img_file, img_label in test_set:\n",
    "    try:\n",
    "        path = ''.join([str(source_path).replace('\\\\', '/'), '/', str(categories[img_label])])\n",
    "        img_file_path = ''.join([str(path), \"/\", str(img_file)])\n",
    "        img = cv2.imread(img_file_path)\n",
    "        for (i, j) in roi1:\n",
    "            x, y = i * width, j * height\n",
    "            roi_img = img[y:y + width, x:x + height]\n",
    "            test_image1.append(roi_img)\n",
    "            test_label1.append(img_label)\n",
    "            \n",
    "    except Exception as err:\n",
    "        print(f'image processing failed at {str(img_file)}')\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_img).reshape(-1, 150, 150, 3)\n",
    "y_train = np.array(train_label)\n",
    "x_train1 = np.array(train_img1).reshape(-1, 150, 150, 3)\n",
    "y_train1 = np.array(train_label1)\n",
    "\n",
    "x_test = np.array(test_image).reshape(-1, 150, 150, 3)\n",
    "y_test = np.array(test_label)\n",
    "x_test1 = np.array(test_image1).reshape(-1, 150, 150, 3)\n",
    "y_test1 = np.array(test_label1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train1 = x_train1 / 255.0\n",
    "x_test1 = x_test1 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, classnum)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, classnum)\n",
    "y_train1 = tf.keras.utils.to_categorical(y_train1, classnum)\n",
    "y_test1 = tf.keras.utils.to_categorical(y_test1, classnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 150, 150, 3) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = Input(shape = x_train[0].shape)\n",
    "input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(32, kernel_size = (3,3), strides = (1,1), kernel_initializer='he_uniform', name= 'conv2d_1')(input_layer)\n",
    "x = BatchNormalization(name = 'BatchNormal_1')(x)\n",
    "x = Activation('relu', name='Activation_1')(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size = (3, 3), strides = (1, 1), kernel_initializer = 'he_uniform', name = 'conv2d_2')(x)\n",
    "x = Activation('relu', name='Activation_2')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2), name = 'MaxPool_1')(x)\n",
    "\n",
    "x = Conv2D(128, kernel_size = (3, 3), strides = (1, 1), kernel_initializer = 'he_uniform', name = 'conv2d_3')(x)\n",
    "x = Activation('relu', name='Activation_3')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2), name = 'MaxPool_2')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "x = Dense(64, activation='relu', kernel_initializer= 'he_uniform')(x)\n",
    "x = Dropout(0.35)(x)\n",
    "x = Dense(32, activation='relu', kernel_initializer= 'he_uniform')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(classnum)(x)\n",
    "output_layer = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_og = Sequential()\n",
    "model_og.add(Conv2D(16, kernel_size=(3,3), strides = (1,1), activation='relu', input_shape(height, width, 3)))\n",
    "model_og.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_layer , output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Model(input_layer , output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "BatchNormal_1 (BatchNormaliz (None, 148, 148, 32)      128       \n",
      "_________________________________________________________________\n",
      "Activation_1 (Activation)    (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 146, 146, 64)      18496     \n",
      "_________________________________________________________________\n",
      "Activation_2 (Activation)    (None, 146, 146, 64)      0         \n",
      "_________________________________________________________________\n",
      "MaxPool_1 (MaxPooling2D)     (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 71, 71, 128)       73856     \n",
      "_________________________________________________________________\n",
      "Activation_3 (Activation)    (None, 71, 71, 128)       0         \n",
      "_________________________________________________________________\n",
      "MaxPool_2 (MaxPooling2D)     (None, 35, 35, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 35, 35, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 156800)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               20070528  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 132       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 20,174,372\n",
      "Trainable params: 20,174,308\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/100\n",
      "12800/12800 [==============================] - 21s 2ms/sample - loss: 1.1791 - accuracy: 0.8506 - val_loss: 1.7400 - val_accuracy: 0.4959\n",
      "Epoch 2/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0736 - accuracy: 0.9800 - val_loss: 3.0952 - val_accuracy: 0.5003\n",
      "Epoch 3/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.2109 - accuracy: 0.9163 - val_loss: 0.1443 - val_accuracy: 0.9884\n",
      "Epoch 4/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0582 - accuracy: 0.9909 - val_loss: 0.0114 - val_accuracy: 0.9991\n",
      "Epoch 5/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0261 - accuracy: 0.9930 - val_loss: 0.6027 - val_accuracy: 0.9481\n",
      "Epoch 6/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.7859 - accuracy: 0.9288 - val_loss: 0.9750 - val_accuracy: 0.8019\n",
      "Epoch 7/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.3192 - accuracy: 0.9789 - val_loss: 4.4799 - val_accuracy: 0.8106\n",
      "Epoch 8/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0397 - accuracy: 0.9943 - val_loss: 0.3650 - val_accuracy: 0.8778\n",
      "Epoch 9/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0423 - accuracy: 0.9918 - val_loss: 0.1903 - val_accuracy: 0.9425\n",
      "Epoch 10/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0730 - accuracy: 0.9773 - val_loss: 0.0126 - val_accuracy: 0.9994\n",
      "Epoch 11/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0272 - accuracy: 0.9962 - val_loss: 0.0174 - val_accuracy: 0.9991\n",
      "Epoch 12/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.0021 - val_accuracy: 0.9997\n",
      "Epoch 13/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.1785 - accuracy: 0.9403 - val_loss: 0.0981 - val_accuracy: 0.9669\n",
      "Epoch 14/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0221 - accuracy: 0.9965 - val_loss: 9.8384e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0128 - accuracy: 0.9972 - val_loss: 3.0241e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0130 - accuracy: 0.9973 - val_loss: 4.2616e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0093 - accuracy: 0.9979 - val_loss: 1.5089e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0083 - accuracy: 0.9977 - val_loss: 3.3577e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0096 - accuracy: 0.9981 - val_loss: 4.8286e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0093 - accuracy: 0.9984 - val_loss: 6.9844e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0082 - accuracy: 0.9986 - val_loss: 8.8767e-04 - val_accuracy: 0.9994\n",
      "Epoch 22/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0058 - accuracy: 0.9987 - val_loss: 6.2806e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.2407 - accuracy: 0.9167 - val_loss: 0.0544 - val_accuracy: 0.9853\n",
      "Epoch 24/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0536 - accuracy: 0.9891 - val_loss: 0.0037 - val_accuracy: 0.9984\n",
      "Epoch 25/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0177 - accuracy: 0.9959 - val_loss: 0.0208 - val_accuracy: 0.9962\n",
      "Epoch 26/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0598 - accuracy: 0.9926 - val_loss: 0.0286 - val_accuracy: 0.9950\n",
      "Epoch 27/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0182 - accuracy: 0.9970 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0225 - accuracy: 0.9962 - val_loss: 0.0242 - val_accuracy: 0.9969\n",
      "Epoch 29/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0180 - accuracy: 0.9973 - val_loss: 6.1771e-04 - val_accuracy: 0.9997\n",
      "Epoch 30/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0144 - accuracy: 0.9970 - val_loss: 5.6845e-04 - val_accuracy: 0.9997\n",
      "Epoch 31/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0848 - accuracy: 0.9956 - val_loss: 0.4967 - val_accuracy: 0.9684\n",
      "Epoch 32/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0760 - accuracy: 0.9970 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
      "Epoch 33/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.4179 - accuracy: 0.9545 - val_loss: 529.1376 - val_accuracy: 0.5116\n",
      "Epoch 34/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.1580 - accuracy: 0.9577 - val_loss: 0.0699 - val_accuracy: 0.9956\n",
      "Epoch 35/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0914 - accuracy: 0.9761 - val_loss: 0.0403 - val_accuracy: 0.9969\n",
      "Epoch 36/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0620 - accuracy: 0.9872 - val_loss: 0.0210 - val_accuracy: 0.9953\n",
      "Epoch 37/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0567 - accuracy: 0.9851 - val_loss: 0.0127 - val_accuracy: 0.9959\n",
      "Epoch 38/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0628 - accuracy: 0.9896 - val_loss: 0.0114 - val_accuracy: 0.9966\n",
      "Epoch 39/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0255 - accuracy: 0.9937 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 40/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0273 - accuracy: 0.9940 - val_loss: 0.0057 - val_accuracy: 0.9984\n",
      "Epoch 41/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0224 - accuracy: 0.9952 - val_loss: 0.0043 - val_accuracy: 0.9991\n",
      "Epoch 42/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0210 - accuracy: 0.9959 - val_loss: 0.0035 - val_accuracy: 0.9991\n",
      "Epoch 43/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0041 - val_accuracy: 0.9991\n",
      "Epoch 44/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0276 - val_accuracy: 0.9944\n",
      "Epoch 45/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 46/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0285 - accuracy: 0.9934 - val_loss: 0.0246 - val_accuracy: 0.9959\n",
      "Epoch 47/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0453 - accuracy: 0.9891 - val_loss: 0.0033 - val_accuracy: 0.9991\n",
      "Epoch 48/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0260 - accuracy: 0.9959 - val_loss: 0.0109 - val_accuracy: 0.9969\n",
      "Epoch 49/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0246 - accuracy: 0.9948 - val_loss: 0.0038 - val_accuracy: 0.9991\n",
      "Epoch 50/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0230 - accuracy: 0.9964 - val_loss: 0.0027 - val_accuracy: 0.9991\n",
      "Epoch 51/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.0237 - val_accuracy: 0.9959\n",
      "Epoch 52/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0217 - accuracy: 0.9945 - val_loss: 0.0039 - val_accuracy: 0.9991\n",
      "Epoch 53/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 54/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0116 - accuracy: 0.9976 - val_loss: 0.0045 - val_accuracy: 0.9991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0040 - val_accuracy: 0.9991\n",
      "Epoch 56/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
      "Epoch 57/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0076 - accuracy: 0.9989 - val_loss: 0.0017 - val_accuracy: 0.9991\n",
      "Epoch 58/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.0034 - val_accuracy: 0.9991\n",
      "Epoch 59/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.0063 - val_accuracy: 0.9991\n",
      "Epoch 60/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0063 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 61/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0044 - val_accuracy: 0.9991\n",
      "Epoch 62/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.0056 - val_accuracy: 0.9991\n",
      "Epoch 63/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0114 - accuracy: 0.9984 - val_loss: 0.0097 - val_accuracy: 0.9987\n",
      "Epoch 64/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0106 - accuracy: 0.9976 - val_loss: 0.0273 - val_accuracy: 0.9962\n",
      "Epoch 65/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.1918 - accuracy: 0.9804 - val_loss: 0.7386 - val_accuracy: 0.9606\n",
      "Epoch 66/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0473 - accuracy: 0.9897 - val_loss: 0.0054 - val_accuracy: 0.9981\n",
      "Epoch 67/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0184 - accuracy: 0.9971 - val_loss: 0.0060 - val_accuracy: 0.9987\n",
      "Epoch 68/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0347 - accuracy: 0.9954 - val_loss: 0.0032 - val_accuracy: 0.9991\n",
      "Epoch 69/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0239 - accuracy: 0.9973 - val_loss: 0.0699 - val_accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0266 - accuracy: 0.9976 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
      "Epoch 71/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0023 - val_accuracy: 0.9991\n",
      "Epoch 72/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.0024 - val_accuracy: 0.9991\n",
      "Epoch 73/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0156 - accuracy: 0.9973 - val_loss: 0.0053 - val_accuracy: 0.9987\n",
      "Epoch 74/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0062 - accuracy: 0.9987 - val_loss: 0.0024 - val_accuracy: 0.9991\n",
      "Epoch 75/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0055 - val_accuracy: 0.9991\n",
      "Epoch 76/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.0042 - val_accuracy: 0.9991\n",
      "Epoch 77/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.1509 - accuracy: 0.9557 - val_loss: 0.0136 - val_accuracy: 0.9984\n",
      "Epoch 78/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.0123 - val_accuracy: 0.9987\n",
      "Epoch 79/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0403 - accuracy: 0.9818 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 80/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0247 - accuracy: 0.9938 - val_loss: 0.0039 - val_accuracy: 0.9987\n",
      "Epoch 81/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0153 - accuracy: 0.9970 - val_loss: 0.0041 - val_accuracy: 0.9987\n",
      "Epoch 82/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0136 - accuracy: 0.9978 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 83/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0157 - accuracy: 0.9973 - val_loss: 0.0036 - val_accuracy: 0.9987\n",
      "Epoch 84/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0110 - val_accuracy: 0.9978\n",
      "Epoch 85/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.0031 - val_accuracy: 0.9991\n",
      "Epoch 86/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0077 - accuracy: 0.9989 - val_loss: 0.0029 - val_accuracy: 0.9991\n",
      "Epoch 87/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0130 - accuracy: 0.9976 - val_loss: 0.0024 - val_accuracy: 0.9991\n",
      "Epoch 88/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.1136 - accuracy: 0.9846 - val_loss: 0.0873 - val_accuracy: 0.9616\n",
      "Epoch 89/100\n",
      "12800/12800 [==============================] - 17s 1ms/sample - loss: 0.0753 - accuracy: 0.9784 - val_loss: 0.0056 - val_accuracy: 0.9987\n",
      "Epoch 90/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0424 - accuracy: 0.9883 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
      "Epoch 91/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0421 - accuracy: 0.9884 - val_loss: 0.0072 - val_accuracy: 0.9975\n",
      "Epoch 92/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0371 - accuracy: 0.9902 - val_loss: 0.0098 - val_accuracy: 0.9975\n",
      "Epoch 93/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0307 - accuracy: 0.9914 - val_loss: 0.0077 - val_accuracy: 0.9978\n",
      "Epoch 94/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.0077 - val_accuracy: 0.9978\n",
      "Epoch 95/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0055 - val_accuracy: 0.9981\n",
      "Epoch 96/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0128 - val_accuracy: 0.9937\n",
      "Epoch 97/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.0053 - val_accuracy: 0.9981\n",
      "Epoch 98/100\n",
      "12800/12800 [==============================] - 18s 1ms/sample - loss: 0.0116 - accuracy: 0.9970 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
      "Epoch 99/100\n",
      "12800/12800 [==============================] - 107s 8ms/sample - loss: 0.0070 - accuracy: 0.9984 - val_loss: 0.0067 - val_accuracy: 0.9981\n",
      "Epoch 100/100\n",
      "12800/12800 [==============================] - 117s 9ms/sample - loss: 0.0100 - accuracy: 0.9979 - val_loss: 0.0058 - val_accuracy: 0.9981\n"
     ]
    }
   ],
   "source": [
    "histoy = model.fit(x_train, y_train, batch_size=128, epochs=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 84s 11ms/sample - loss: 2.1565 - accuracy: 0.9438 - val_loss: 0.2769 - val_accuracy: 0.9820\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0666 - accuracy: 0.9910 - val_loss: 0.1030 - val_accuracy: 0.9970\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0825 - accuracy: 0.9916 - val_loss: 0.0199 - val_accuracy: 0.9985\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0217 - accuracy: 0.9962 - val_loss: 0.0112 - val_accuracy: 0.9980\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0222 - accuracy: 0.9952 - val_loss: 0.0086 - val_accuracy: 0.9985\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 72s 9ms/sample - loss: 0.0168 - accuracy: 0.9977 - val_loss: 0.0486 - val_accuracy: 0.9945\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 72s 9ms/sample - loss: 0.0402 - accuracy: 0.9956 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0223 - accuracy: 0.9954 - val_loss: 0.0014 - val_accuracy: 0.9995\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 74s 9ms/sample - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0531 - val_accuracy: 0.9990\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 72s 9ms/sample - loss: 0.0191 - accuracy: 0.9977 - val_loss: 0.0166 - val_accuracy: 0.9990\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0336 - accuracy: 0.9983 - val_loss: 0.0145 - val_accuracy: 0.9990\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.1546 - accuracy: 0.9893 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0067 - accuracy: 0.9983 - val_loss: 5.8284e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 71s 9ms/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 9.9916e-04 - val_accuracy: 0.9995\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 46s 6ms/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 2.4728e-07 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 3.7711e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 1.2885e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0055 - accuracy: 0.9986 - val_loss: 2.1754e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0074 - accuracy: 0.9986 - val_loss: 8.3211e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0038 - accuracy: 0.9991 - val_loss: 8.8285e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0040 - accuracy: 0.9992 - val_loss: 3.4411e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.0308 - val_accuracy: 0.9995\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0187 - accuracy: 0.9971 - val_loss: 1.3954e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0054 - accuracy: 0.9987 - val_loss: 8.5159e-04 - val_accuracy: 0.9995\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0069 - accuracy: 0.9983 - val_loss: 9.6894e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0019 - accuracy: 0.9992 - val_loss: 2.6209e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 6.6707e-07 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0036 - accuracy: 0.9992 - val_loss: 5.8737e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0075 - accuracy: 0.9989 - val_loss: 1.9638e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0353 - accuracy: 0.9952 - val_loss: 0.0139 - val_accuracy: 0.9985\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0197 - accuracy: 0.9970 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0080 - accuracy: 0.9985 - val_loss: 7.2277e-04 - val_accuracy: 0.9995\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0043 - val_accuracy: 0.9995\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0010 - val_accuracy: 0.9995\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0056 - accuracy: 0.9987 - val_loss: 2.0182e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0028 - accuracy: 0.9994 - val_loss: 6.2081e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0121 - accuracy: 0.9974 - val_loss: 8.3818e-04 - val_accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0064 - accuracy: 0.9990 - val_loss: 6.9937e-04 - val_accuracy: 0.9995\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 3.9239e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0159 - accuracy: 0.9981 - val_loss: 1.7910e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0105 - accuracy: 0.9981 - val_loss: 5.6384e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 1.0666e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0030 - accuracy: 0.9992 - val_loss: 1.7556e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0050 - accuracy: 0.9986 - val_loss: 2.7629e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 15s 2ms/sample - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0021 - val_accuracy: 0.9990\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 14s 2ms/sample - loss: 0.0083 - accuracy: 0.9989 - val_loss: 0.0055 - val_accuracy: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0038 - accuracy: 0.9987 - val_loss: 9.0426e-04 - val_accuracy: 0.9995\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.7866e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 8.7919e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0018 - accuracy: 0.9996 - val_loss: 1.6323e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0034 - accuracy: 0.9990 - val_loss: 1.1037e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0044 - accuracy: 0.9991 - val_loss: 8.5774e-07 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.8656e-08 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0149 - accuracy: 0.9995 - val_loss: 0.0091 - val_accuracy: 0.9985\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0012 - val_accuracy: 0.9995\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0792 - val_accuracy: 0.9990\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0089 - accuracy: 0.9995 - val_loss: 1.6532e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0024 - accuracy: 0.9995 - val_loss: 3.7304e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.0578 - val_accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0818 - val_accuracy: 0.9995\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0083 - val_accuracy: 0.9995\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0109 - accuracy: 0.9987 - val_loss: 1.1698e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 6.1826e-04 - accuracy: 1.0000 - val_loss: 4.1490e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 2.5261e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0034 - accuracy: 0.9990 - val_loss: 2.3720e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 3.8921e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0010 - accuracy: 0.9999 - val_loss: 3.5520e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0015 - accuracy: 0.9998 - val_loss: 3.6376e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0034 - accuracy: 0.9994 - val_loss: 3.4165e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0023 - accuracy: 0.9998 - val_loss: 1.9306e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0034 - accuracy: 0.9992 - val_loss: 3.8312e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0345 - accuracy: 0.9958 - val_loss: 0.1307 - val_accuracy: 0.9935\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0586 - accuracy: 0.9958 - val_loss: 17.9194 - val_accuracy: 0.7660\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 8.2745 - val_accuracy: 0.8835\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0228 - val_accuracy: 0.9995\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0179 - accuracy: 0.9984 - val_loss: 1.5023e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0040 - accuracy: 0.9991 - val_loss: 4.5895e-09 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0102 - accuracy: 0.9995 - val_loss: 1.4484e-08 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.2190 - accuracy: 0.9936 - val_loss: 13.9626 - val_accuracy: 0.7515\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.1055 - accuracy: 0.9931 - val_loss: 1.2591 - val_accuracy: 0.7515\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0358 - accuracy: 0.9962 - val_loss: 1.7937 - val_accuracy: 0.8510\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0171 - accuracy: 0.9980 - val_loss: 0.1480 - val_accuracy: 0.9875\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0069 - accuracy: 0.9990 - val_loss: 6.6697e-07 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0116 - accuracy: 0.9974 - val_loss: 3.1092e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0063 - accuracy: 0.9986 - val_loss: 1.4822e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0150 - accuracy: 0.9987 - val_loss: 4.9339e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0079 - accuracy: 0.9989 - val_loss: 1.3540e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0186 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0025 - val_accuracy: 0.9990\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.0052 - val_accuracy: 0.9995\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0449 - accuracy: 0.9970 - val_loss: 0.0108 - val_accuracy: 0.9995\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 13s 2ms/sample - loss: 0.0095 - accuracy: 0.9990 - val_loss: 0.0120 - val_accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "history = model_1.fit(x_train1, y_train1, batch_size=128, epochs=100, validation_data=(x_test1, y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 5s 2ms/sample - loss: 0.0058 - accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005844703167576868, 0.998125]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 622us/sample - loss: 5.1270e-04 - accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.000512703403820467, 0.9995]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(x_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.6762491e-24, 1.5807950e-11, 1.8663003e-16, 1.0000000e+00],\n",
       "       [1.3650158e-35, 2.6829949e-17, 2.3242266e-23, 1.0000000e+00],\n",
       "       [0.0000000e+00, 2.6005958e-25, 8.6419688e-32, 1.0000000e+00],\n",
       "       ...,\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       800\n",
      "           1       0.99      1.00      1.00       800\n",
      "           2       1.00      1.00      1.00       800\n",
      "           3       1.00      0.99      1.00       800\n",
      "\n",
      "    accuracy                           1.00      3200\n",
      "   macro avg       1.00      1.00      1.00      3200\n",
      "weighted avg       1.00      1.00      1.00      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, x_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = r'D:\\Working_dir\\53R_203\\2021-01-16\\202\\normal_day'\n",
    "test_path = test_path.replace('\\\\', '/')\n",
    "testimg_list = fnmatch.filter(os.listdir(test_path), \"*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[2, 0, 6, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[6, 0, 2, 0]\n",
      "[6, 0, 2, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[6, 0, 2, 0]\n",
      "[6, 0, 2, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[0, 0, 8, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[5, 0, 3, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[2, 0, 6, 0]\n",
      "[8, 0, 0, 0]\n",
      "[0, 0, 8, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[4, 0, 4, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[5, 0, 3, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[2, 0, 6, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[7, 0, 1, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "[8, 0, 0, 0]\n",
      "97.99%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for imgs in testimg_list:\n",
    "    roi_set = []\n",
    "    img_path = f\"{test_path}/{imgs}\"\n",
    "    img = cv2.imread(img_path)\n",
    "    for (i,j) in roi0:\n",
    "        x,y = i * width, j * height\n",
    "        roi_img = img[y:y+height, x:x+width]\n",
    "        roi_set.append(roi_img)\n",
    "        \n",
    "    roi_set = np.array(roi_set)/255.\n",
    "    roi_set = roi_set.reshape(-1, width, height,3)\n",
    "    \n",
    "    preds = model_test.predict(roi_set)\n",
    "    pred_values =[]\n",
    "    \n",
    "    for pred in preds:\n",
    "        pred_values.append(np.argmax(pred))\n",
    "        \n",
    "    pred_list = []\n",
    "    \n",
    "    for i in range(len(categories)):\n",
    "        pred_list.append(pred_values.count(i))\n",
    "        \n",
    "    print(pred_list)\n",
    "    if np.argmax(pred_list) == 0:\n",
    "        count += 1\n",
    "        \n",
    "#         os.mkdir(f'{test_path}/{categories[2]}')\n",
    "#         shutil.move(f'{test_path}/{testimg_list}', f'{test_path}/fog_day/{testimg_list}')\n",
    "        \n",
    "#     elif np.argmax(pred_list) == 3:\n",
    "#         count += 1\n",
    "        \n",
    "#         os.mkdir(f'{test_path}/{categories[3]}')\n",
    "#         shutil.move(f'{test_path}/{testimg_list}', f'{test_path}/fog_night/{testimg_list}')\n",
    "            \n",
    "    \n",
    "print(f\"{count / len(testimg_list) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델(fog0) 저장\n",
    "# tf.keras.models.save_model(model,'D:/Working_dir/Ehwlfkfdlsp/model.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
